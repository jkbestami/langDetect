[HEADER]
[HEADER:DATASOURCE]
rawFile=FILE_RAW
sourceFile=
sourceFormat=
sourceHeaders=f
[SETUP]
[SETUP:CONFIG]
allowedClasses=integer,string
csvFormat=decpnt|comma
inputHeaders=f
maxClassCount=50
[SETUP:FILENAMES]
FILE_RANDOMIZE=input_random.csv
FILE_TRAIN=input_train.csv
FILE_RAW=input.csv
FILE_TRAINSET=input_train.egb
FILE_CLUSTER=input_cluster.csv
FILE_OUTPUT=input_output.csv
FILE_EVAL=input_eval.csv
FILE_ML=input_train.eg
FILE_NORMALIZE=input_norm.csv
FILE_EVAL_NORM=input_eval_norm.csv
[DATA]
[DATA:CONFIG]
goal=classification
[DATA:STATS]
"name","isclass","iscomplete","isint","isreal","amax","amin","mean","sdev","source"
"field:1",1,1,0,0,0.0001,-0.0001,0,0,""
"field:2",1,1,0,0,0.0001,-0.0001,0,0,""
"field:3",1,1,0,0,0.0001,-0.0001,0,0,""
"field:4",1,1,0,0,0.0001,-0.0001,0,0,""
"field:5",1,1,0,0,0.0001,-0.0001,0,0,""
"field:6",1,1,0,0,0.0001,-0.0001,0,0,""
"field:7",1,1,0,0,0.0001,-0.0001,0,0,""
"field:8",1,1,0,0,0.0001,-0.0001,0,0,""
"field:9",1,1,0,0,0.0001,-0.0001,0,0,""
"field:10",1,1,0,0,0.0001,-0.0001,0,0,""
"field:11",1,1,0,0,0.0001,-0.0001,0,0,""
"field:12",1,1,0,0,0.0001,-0.0001,0,0,""
"field:13",1,1,0,0,0.0001,-0.0001,0,0,""
"field:14",1,1,0,0,0.0001,-0.0001,0,0,""
"field:15",1,1,0,0,0.0001,-0.0001,0,0,""
"field:16",1,1,0,0,0.0001,-0.0001,0,0,""
"field:17",1,1,0,0,0.0001,-0.0001,0,0,""
[DATA:CLASSES]
"field","code","name","count"
"field:1","1.0","1.0",1
"field:1","dDouble","dDouble",1
"field:2","1.0","1.0",1
"field:2","fDouble","fDouble",1
"field:3","0.0","0.0",1
"field:3","eDouble","eDouble",1
"field:4","0.0","0.0",1
"field:4","dTriple","dTriple",1
"field:5","0.0","0.0",1
"field:5","fTriple","fTriple",1
"field:6","0.0","0.0",1
"field:6","eTriple","eTriple",1
"field:7","0.0","0.0",1
"field:7","dQuad","dQuad",1
"field:8","0.0","0.0",1
"field:8","fQuad","fQuad",1
"field:9","0.0","0.0",1
"field:9","eQuad","eQuad",1
"field:10","1.0","1.0",1
"field:10","dDuo","dDuo",1
"field:11","1.0","1.0",1
"field:11","fDuo","fDuo",1
"field:12","1.0","1.0",1
"field:12","eDuo","eDuo",1
"field:13","3.0","3.0",1
"field:13","mcd","mcd",1
"field:14","3.0","3.0",1
"field:14","mcf","mcf",1
"field:15","3.0","3.0",1
"field:15","mce","mce",1
"field:16","5.0","5.0",1
"field:16","length","length",1
"field:17","french","french",1
"field:17","language","language",1
[NORMALIZE]
[NORMALIZE:CONFIG]
missingValues=DiscardMissing
sourceFile=FILE_TRAIN
targetFile=FILE_NORMALIZE
[NORMALIZE:RANGE]
"name","io","timeSlice","action","high","low"
"field:1","input",0,"oneof",1,0
"field:2","input",0,"oneof",1,0
"field:3","input",0,"oneof",1,0
"field:4","input",0,"oneof",1,0
"field:5","input",0,"oneof",1,0
"field:6","input",0,"oneof",1,0
"field:7","input",0,"oneof",1,0
"field:8","input",0,"oneof",1,0
"field:9","input",0,"oneof",1,0
"field:10","input",0,"oneof",1,0
"field:11","input",0,"oneof",1,0
"field:12","input",0,"oneof",1,0
"field:13","input",0,"oneof",1,0
"field:14","input",0,"oneof",1,0
"field:15","input",0,"oneof",1,0
"field:16","input",0,"oneof",1,0
"field:17","output",0,"oneof",1,0
[PROCESS]
[PROCESS:CONFIG]
backwardSize=
forwardSize=
sourceFile=
targetFile=
[PROCESS:FIELDS]
"name","command"
[RANDOMIZE]
[RANDOMIZE:CONFIG]
sourceFile=FILE_RAW
targetFile=FILE_RANDOMIZE
[CLUSTER]
[CLUSTER:CONFIG]
clusters=2
sourceFile=FILE_EVAL
targetFile=FILE_CLUSTER
type=kmeans
[BALANCE]
[BALANCE:CONFIG]
balanceField=
countPer=
sourceFile=
targetFile=
[CODE]
[CODE:CONFIG]
embedData=f
targetFile=FILE_CODE
targetLanguage=NOGENERATION
[SEGREGATE]
[SEGREGATE:CONFIG]
sourceFile=FILE_RANDOMIZE
[SEGREGATE:FILES]
"file","percent"
"FILE_TRAIN",75
"FILE_EVAL",25
[GENERATE]
[GENERATE:CONFIG]
sourceFile=FILE_NORMALIZE
targetFile=FILE_TRAINSET
[ML]
[ML:CONFIG]
architecture=?:B->SIGMOID->48:B->SIGMOID->?
evalFile=FILE_EVAL
machineLearningFile=FILE_ML
outputFile=FILE_OUTPUT
query=
trainingFile=FILE_TRAINSET
type=feedforward
[ML:TRAIN]
arguments=
cross=
targetError=0.25
type=rprop
[ML:OPCODES]
"code","count"
[TASKS]
[TASKS:task-cluster]
cluster
[TASKS:task-code]
code
[TASKS:task-create]
create
[TASKS:task-evaluate]
evaluate
[TASKS:task-evaluate-raw]
set ML.CONFIG.evalFile="FILE_EVAL_NORM"
set NORMALIZE.CONFIG.sourceFile="FILE_EVAL"
set NORMALIZE.CONFIG.targetFile="FILE_EVAL_NORM"
normalize
evaluate-raw
[TASKS:task-full]
randomize
segregate
normalize
generate
create
train
evaluate
[TASKS:task-generate]
randomize
segregate
normalize
generate
[TASKS:task-train]
train
